```r
library(dplyr)
```

The main idea behind grouping data is that you want to break up your dataset into groups of rows based on the values of one or more variables. The `group_by()` function is responsible for doing this.

Group cran by the package variable and store the result in a new variable called by_package: `by_package <- group_by(cran, package)`

```r
> by_package
Source: local data frame [225,468 x 11]
Groups: package

    X       date     time    size r_version r_arch      r_os      package version country ip_id
1   1 2014-07-08 00:54:41   80589     3.1.0 x86_64   mingw32    htmltools   0.2.4      US     1
2   2 2014-07-08 00:59:53  321767     3.1.0 x86_64   mingw32      tseries 0.10-32      US     2
3   3 2014-07-08 00:47:13  748063     3.1.0 x86_64 linux-gnu        party  1.0-15      US     3
4   4 2014-07-08 00:48:05  606104     3.1.0 x86_64 linux-gnu        Hmisc  3.14-4      US     3
5   5 2014-07-08 00:46:50   79825     3.0.2 x86_64 linux-gnu       digest   0.6.4      CA     4
6   6 2014-07-08 00:48:04   77681     3.1.0 x86_64 linux-gnu randomForest   4.6-7      US     3
7   7 2014-07-08 00:48:35  393754     3.1.0 x86_64 linux-gnu         plyr   1.8.1      US     3
8   8 2014-07-08 00:47:30   28216     3.0.2 x86_64 linux-gnu      whisker   0.3-2      US     5
9   9 2014-07-08 00:54:58    5928        NA     NA        NA         Rcpp  0.10.4      CN     6
10 10 2014-07-08 00:15:35 2206029     3.0.2 x86_64 linux-gnu     hflights     0.1      US     7
.. ..        ...      ...     ...       ...    ...       ...          ...     ...     ...   ...
```

At the top of the output above, you'll see 'Groups: package', which tells us that this tbl has been grouped by the package variable. Everything else looks the same, but now any operation we apply to the grouped data will take place on a per package basis.

Recall that when we applied `mean(size)` to the original tbl_df via `summarize()`, it returned a single number -- the mean of all values in the size column. We may care about what that number is, but wouldn't it be so much more interesting to look at the mean download size for each unique package? That's exactly what you'll get if you use `summarize()` to apply `mean(size)` to the grouped data in by_package.

```r
> summarize(by_package, mean(size))
Source: local data frame [6,023 x 2]

       package mean(size)
1           A3   62194.96
2  ABCExtremes   22904.33
3     ABCoptim   17807.25
4        ABCp2   30473.33
5       ACCLMA   33375.53
6          ACD   99055.29
7         ACNE   96099.75
8        ACTCD  134746.27
9    ADGofTest   12262.91
10        ADM3 1077203.47
..         ...        ...
```

Instead of returning a single value, `summarize()` now returns the mean size for EACH package in our dataset.

```r
# Compute four values, in the following order, from
# the grouped data:
#
# 1. count = n()
# 2. unique = n_distinct(ip_id)
# 3. countries = n_distinct(country)
# 4. avg_bytes = mean(size)
#
# A few thing to be careful of:
#
# 1. Separate arguments by commas
# 2. Make sure you have a closing parenthesis
# 3. Check your spelling!
# 4. Store the result in pack_sum (for 'package summary')
#
# You should also take a look at ?n and ?n_distinct, so
# that you really understand what is going on.

pack_sum <- summarize(by_package,
  count = n(),
  unique = n_distinct(ip_id),
  countries = n_distinct(country),
  avg_bytes = mean(size))

###############################

Source: local data frame [6,023 x 5]

       package count unique countries  avg_bytes
1           A3    25     24        10   62194.96
2  ABCExtremes    18     17         9   22904.33
3     ABCoptim    16     15         9   17807.25
4        ABCp2    18     17        10   30473.33
5       ACCLMA    15     14         9   33375.53
6          ACD    17     16        10   99055.29
7         ACNE    16     15        10   96099.75
8        ACTCD    15     14         9  134746.27
9    ADGofTest    47     44        20   12262.91
10        ADM3    17     16        10 1077203.47
  ..         ...   ...    ...       ...        ...
```

The 'count' column, created with `n()`, contains the total number of rows (i.e. downloads) for each package. The 'unique' column, created with `n_distinct(ip_id)`, gives the total number of unique downloads for each package, as measured by the number of distinct ip_id's. The 'countries' column, created with `n_distinct(country)`, provides the number of countries in which each package was downloaded. And finally, the 'avg_bytes' column, created with `mean(size)`, contains the mean download size (in bytes) for each package.

Naturally, we'd like to know which packages were most popular on the day these data were collected (July 8, 2014). Let's start by isolating the top 1% of packages, based on the total number of downloads as measured by the 'count' column.

We need to know the value of 'count' that splits the data into the top 1% and bottom 99% of packages based on total downloads. In statistics, this is called the 0.99, or 99%, sample quantile. Use `quantile(pack_sum$count, probs = 0.99)` to determine this number.

```r
> quantile(pack_sum$count, probs = 0.99)
   99%
679.56
```

Use `filter()` to select all rows from pack_sum for which 'count' is strictly greater (>) than 679. Store the result in a new variable called top_counts:

```r
> top_counts <- filter(pack_sum, count > 679)
Source: local data frame [61 x 5]

        package count unique countries   avg_bytes
1           DBI  2599    492        48  206933.250
2       Formula   852    777        65  155742.002
3         Hmisc   954    812        69 1367675.911
4          LPCM  2335     17        10  526814.226
5          MASS   834    698        66  981152.179
6        Matrix   932    801        66 3220134.165
7  RColorBrewer  1890   1584        79   22763.995
8         RCurl  1504   1207        73 1903505.324
9         RJDBC   809    107        28   18715.441
10      RJSONIO   751    585        60 1208103.992
```

`arrange() `the rows of top_counts based on the 'count' column. We want the packages with the highest number of downloads at the top, which means we want 'count' to be in descending order

```r
> arrange(top_counts, desc(count))
Source: local data frame [61 x 5]

        package count unique countries   avg_bytes
1       ggplot2  4602   1680        81 2427716.054
2          Rcpp  3195   2044        84 2512100.355
3          plyr  2908   1754        81  799122.790
4         rJava  2773    963        70  633522.348
5           DBI  2599    492        48  206933.250
6          LPCM  2335     17        10  526814.226
7       stringr  2267   1948        82   65277.166
8        digest  2210   1894        83  120549.294
9      reshape2  2032   1652        76  330128.263
10      foreach  1984    485        53  358069.782
```

Perhaps we're more interested in the number of **unique** downloads on this particular day. In other words, if a package is downloaded ten times in one day from the same computer, we may wish to count that as only one download. That's what the 'unique' column will tell us. Like we did with 'count', let's find the 0.99, or 99%, quantile for the 'unique' variable with `quantile(pack_sum$unique, probs = 0.99)`.

```r
> quantile(pack_sum$unique, probs = 0.99)
99%
465
```

Apply `filter()` to pack_sum to select all rows corresponding to values of 'unique' that are strictly greater than 465. Assign the result to a variable called top_unique

```r
> top_unique <- filter(pack_sum, unique > 465)
> top_unique
Source: local data frame [60 x 5]

        package count unique countries  avg_bytes
1           DBI  2599    492        48  206933.25
2       Formula   852    777        65  155742.00
3         Hmisc   954    812        69 1367675.91
4          MASS   834    698        66  981152.18
5        Matrix   932    801        66 3220134.17
6  RColorBrewer  1890   1584        79   22763.99
7         RCurl  1504   1207        73 1903505.32
8       RJSONIO   751    585        60 1208103.99
9          Rcpp  3195   2044        84 2512100.35
10    RcppEigen   546    474        52 2032426.11
```

Now `arrange()` top_unique by the 'unique' column, in descending order, to see which packages were downloaded from the greatest number of unique IP addresses.

```r
> arrange(top_unique, desc(unique))
Source: local data frame [60 x 5]

package count unique countries  avg_bytes
1          Rcpp  3195   2044        84 2512100.35
2       stringr  2267   1948        82   65277.17
3        digest  2210   1894        83  120549.29
4          plyr  2908   1754        81  799122.79
5       ggplot2  4602   1680        81 2427716.05
6      reshape2  2032   1652        76  330128.26
7  RColorBrewer  1890   1584        79   22763.99
8    colorspace  1683   1433        80  357411.20
9        bitops  1549   1408        76   28715.05
10       scales  1726   1408        77  126819.33
```

Our final metric of popularity is the number of distinct countries from which each package was downloaded. We'll approach this one a little differently to introduce you to a method called 'chaining' (or 'piping').

Chaining allows you to string together multiple function calls in a way that is compact and readable, while still accomplishing the desired result.

```r
# Don't change any of the code below. Just type submit()
# when you think you understand it.

# We've already done this part, but we're repeating it
# here for clarity.

by_package <- group_by(cran, package)
pack_sum <- summarize(by_package,
  count = n(),
  unique = n_distinct(ip_id),
  countries = n_distinct(country),
  avg_bytes = mean(size))

# Here's the new bit, but using the same approach we've
# been using this whole time.

top_countries <- filter(pack_sum, countries > 60)
result1 <- arrange(top_countries, desc(countries), avg_bytes)

# Print the results to the console.
print(result1)

###############################

Source: local data frame [46 x 5]

         package count unique countries  avg_bytes
1           Rcpp  3195   2044        84 2512100.35
2         digest  2210   1894        83  120549.29
3        stringr  2267   1948        82   65277.17
4           plyr  2908   1754        81  799122.79
5        ggplot2  4602   1680        81 2427716.05
6     colorspace  1683   1433        80  357411.20
7   RColorBrewer  1890   1584        79   22763.99
8         scales  1726   1408        77  126819.33
9         bitops  1549   1408        76   28715.05
10      reshape2  2032   1652        76  330128.26
```

It's worth noting that we sorted primarily by country, but used avg_bytes (in ascending order) as a tie breaker. This means that if two packages were downloaded from the same number of countries, the package with a smaller average download size received a higher ranking.

We'd like to accomplish the same result as the last script, but avoid saving our intermediate results. This requires embedding function calls within one another.

```r
# Don't change any of the code below. Just type submit()
# when you think you understand it. If you find it
# confusing, you're absolutely right!

result2 <-
arrange(
  filter(
    summarize(
      group_by(cran,
        package
        ),
        count = n(),
        unique = n_distinct(ip_id),
        countries = n_distinct(country),
        avg_bytes = mean(size)
        ),
        countries > 60
        ),
        desc(countries),
        avg_bytes
        )

        print(result2)

###############################

Source: local data frame [46 x 5]

         package count unique countries  avg_bytes
1           Rcpp  3195   2044        84 2512100.35
2         digest  2210   1894        83  120549.29
3        stringr  2267   1948        82   65277.17
4           plyr  2908   1754        81  799122.79
5        ggplot2  4602   1680        81 2427716.05
6     colorspace  1683   1433        80  357411.20
7   RColorBrewer  1890   1584        79   22763.99
8         scales  1726   1408        77  126819.33
9         bitops  1549   1408        76   28715.05
10      reshape2  2032   1652        76  330128.26
```

That's exactly what we've done in this script. The result is equivalent, but the code is much less readable and some of the arguments are far away from the function to which they belong.

```r
# Read the code below, but don't change anything. As
# you read it, you can pronounce the %>% operator as
# the word 'then'.
#
# Type submit() when you think you understand
# everything here.

result3 <-
cran %>%
group_by(package) %>%
summarize(count = n(),
unique = n_distinct(ip_id),
countries = n_distinct(country),
avg_bytes = mean(size)
) %>%
filter(countries > 60) %>%
arrange(desc(countries), avg_bytes)

# Print result to console
print(result3)

###############################

Source: local data frame [46 x 5]

         package count unique countries  avg_bytes
1           Rcpp  3195   2044        84 2512100.35
2         digest  2210   1894        83  120549.29
3        stringr  2267   1948        82   65277.17
4           plyr  2908   1754        81  799122.79
5        ggplot2  4602   1680        81 2427716.05
6     colorspace  1683   1433        80  357411.20
7   RColorBrewer  1890   1584        79   22763.99
8         scales  1726   1408        77  126819.33
9         bitops  1549   1408        76   28715.05
10      reshape2  2032   1652        76  330128.26
```

In this script, we've used a special chaining operator, `%>%`, which is part of the dplyr package. You can pull up the related documentation with ?chain. The benefit of `%>%` is that it allows us to chain the function calls in a linear fashion. The code to the right of `%>%` operates on the result from the code to the left of `%>%`.

```r
# select() the following columns from cran. Keep in mind
# that when you're using the chaining operator, you don't
# need to specify the name of the data tbl in your call to
# select().
#
# 1. ip_id
# 2. country
# 3. package
# 4. size
#
# The call to print() at the end of the chain is optional,
# but necessary if you want your results printed to the
# console. Note that since there are no additional arguments
# to print(), you can leave off the parentheses after
# the function name. This is a convenient feature of the %>%
# operator.

cran %>%
select(ip_id, country, package, size) %>%
print

###############################

Source: local data frame [225,468 x 4]

   ip_id country      package    size
1      1      US    htmltools   80589
2      2      US      tseries  321767
3      3      US        party  748063
4      3      US        Hmisc  606104
5      4      CA       digest   79825
6      3      US randomForest   77681
7      3      US         plyr  393754
8      5      US      whisker   28216
9      6      CN         Rcpp    5928
10     7      US     hflights 2206029
..   ...     ...          ...     ...
```

```r
# Use mutate() to add a column called size_mb that contains
# the size of each download in megabytes (i.e. size / 2^20).
#
# If you want your results printed to the console, add
# print to the end of your chain.

cran %>%
select(ip_id, country, package, size) %>%
mutate(size_mb = size / 2^20) %>%
print

###############################

Source: local data frame [225,468 x 5]

   ip_id country      package    size     size_mb
1      1      US    htmltools   80589 0.076855659
2      2      US      tseries  321767 0.306860924
3      3      US        party  748063 0.713408470
4      3      US        Hmisc  606104 0.578025818
5      4      CA       digest   79825 0.076127052
6      3      US randomForest   77681 0.074082375
7      3      US         plyr  393754 0.375513077
8      5      US      whisker   28216 0.026908875
9      6      CN         Rcpp    5928 0.005653381
10     7      US     hflights 2206029 2.103833199
..   ...     ...          ...     ...         ...
```

```r
# Use filter() to select all rows for which size_mb is
# less than or equal to (<=) 0.5.
#
# If you want your results printed to the console, add
# print to the end of your chain.

cran %>%
select(ip_id, country, package, size) %>%
mutate(size_mb = size / 2^20) %>%
filter(size_mb <= .5) %>%
print

###############################

Source: local data frame [142,021 x 5]

   ip_id country      package   size     size_mb
1      1      US    htmltools  80589 0.076855659
2      2      US      tseries 321767 0.306860924
3      4      CA       digest  79825 0.076127052
4      3      US randomForest  77681 0.074082375
5      3      US         plyr 393754 0.375513077
6      5      US      whisker  28216 0.026908875
7      6      CN         Rcpp   5928 0.005653381
8     13      DE        ipred 186685 0.178036690
9     14      US       mnormt  36204 0.034526825
10    16      US    iterators 289972 0.276538849
..   ...     ...          ...    ...         ...
```

```r
# arrange() the result by size_mb, in descending order.
#
# If you want your results printed to the console, add
# print to the end of your chain.

cran %>%
select(ip_id, country, package, size) %>%
mutate(size_mb = size / 2^20) %>%
filter(size_mb <= 0.5) %>%
arrange(desc(size_mb)) %>%
print

###############################

Source: local data frame [142,021 x 5]

   ip_id country               package   size   size_mb
1  11034      DE                  phia 524232 0.4999466
2   9643      US                   tis 524152 0.4998703
3   1542      IN               RcppSMC 524060 0.4997826
4  12354      US                 lessR 523916 0.4996452
5  12072      US            colorspace 523880 0.4996109
6   2514      KR              depmixS4 523863 0.4995947
7   1111      US              depmixS4 523858 0.4995899
8   8865      CR              depmixS4 523858 0.4995899
9   5908      CN RcmdrPlugin.KMggplot2 523852 0.4995842
10 12354      US RcmdrPlugin.KMggplot2 523852 0.4995842
..   ...     ...                   ...    ...       ...
```
